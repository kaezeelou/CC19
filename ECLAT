{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaezeelou/CC19/blob/master/ECLAT\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzOmzFRvqq8o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "b0c9e28d-7598-4ef1-8024-8c16c2c427fc"
      },
      "source": [
        "import numpy as np, itertools\n",
        "import pandas as pd\n",
        "np.random.seed(1)\n",
        "kot = 0\n",
        "FreqItems = dict()\n",
        "support = dict()\n",
        "\n",
        "\n",
        "def eclat(prefix, items, dict_id):\n",
        "    while items:\n",
        "        i,itids = items.pop()\n",
        "        isupp = len(itids)\n",
        "        if isupp >= minsup:\n",
        "\n",
        "            FreqItems[frozenset(prefix + [i])] = isupp\n",
        "            suffix = []\n",
        "            for j, ojtids in items:\n",
        "                jtids = itids & ojtids\n",
        "                if len(jtids) >= minsup:\n",
        "                    suffix.append((j,jtids))\n",
        "\n",
        "            dict_id += 1\n",
        "            eclat(prefix+[i], sorted(suffix, key=lambda item: len(item[1]), reverse=True), dict_id)\n",
        "\n",
        "def rules(FreqItems, confidence):\n",
        "    Rules = []\n",
        "    cnt = 0\n",
        "\n",
        "    for items, support in FreqItems.items():\n",
        "        if (len(items) > 1):\n",
        "            all_perms = list(itertools.permutations(items, len(items)))\n",
        "            for lst in all_perms:\n",
        "                antecedent = lst[:len(lst) - 1]\n",
        "                consequent = lst[-1:]\n",
        "\n",
        "                conf = float(FreqItems[frozenset(items)]/FreqItems[frozenset(antecedent)]*100)\n",
        "                if (conf >= confidence):\n",
        "                    cnt += 1\n",
        "                    lift = float(conf/FreqItems[frozenset(consequent)])\n",
        "                    if lift >= 1:\n",
        "                        Rules.append((antecedent, consequent, support, conf, lift))\n",
        "\n",
        "\n",
        "    print('Found %d Rules ' % (cnt))\n",
        "    return Rules\n",
        "\n",
        "\n",
        "def getantecendent(FreqItems, confidence):\n",
        "    ant = []\n",
        "    cnt = 0\n",
        "\n",
        "    for items, support in FreqItems.items():\n",
        "        if(len(items) > 1):\n",
        "            all_perms = list(itertools.permutations(items, len(items)))\n",
        "            for lst in all_perms:\n",
        "                antecedent = lst[:len(lst) - 1]\n",
        "                consequent = lst[-1:]\n",
        "\n",
        "                conf = float(FreqItems[frozenset(items)]/FreqItems[frozenset(antecedent)]*100)\n",
        "                if (conf >= confidence):\n",
        "                    cnt += 1\n",
        "                    lift = float(conf/FreqItems[frozenset(consequent)])\n",
        "                    if lift >= 1:\n",
        "                        ant.append((antecedent))\n",
        "\n",
        "    print('Print %d attributes' % (cnt))\n",
        "    return ant\n",
        "\n",
        "def print_Frequent_Itemsets(output_FreqItems, FreqItems):\n",
        "    file = open(output_FreqItems, 'w+')\n",
        "    for item, support in FreqItems.items():\n",
        "        file.write(\" {} : {} \\n\".format(list(item), round(support,4)))\n",
        "\n",
        "def print_Rules(output_Rules, Rules):\n",
        "    file = open(output_Rules, 'w+')\n",
        "    for a, b,supp, conf, lift in sorted(Rules):\n",
        "        file.write(\"{} ==> {} support: {} confidence: {} \\n\".format((a), (b), round(supp, 4),round(conf, 4),round(lift, 4)))\n",
        "    file.close()\n",
        "    \n",
        "def print_Antecendent(ant):\n",
        "    file = open('output_antecendent.csv', 'w+')\n",
        "    for a in sorted(ant):\n",
        "        file.write(\"[] \\n\".format((a)))\n",
        "    file.close()\n",
        "    \n",
        "def Read_Data(filename, delimiter=','):\n",
        "    data = {}\n",
        "    trans = 0\n",
        "    f = open(filename, 'r', encoding=\"utf8\")\n",
        "    for row in f:\n",
        "        trans += 1\n",
        "        for item in row.split(delimiter):\n",
        "            if item not in data:\n",
        "                data[item] = set()\n",
        "            data[item].add(trans)\n",
        "    f.close()\n",
        "    return data\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    minsup   = 3\n",
        "    confidence = 70\n",
        "    output_FreqItems = 'output_freqitems.csv'\n",
        "    output_Rules = 'output_rule.csv'\n",
        "    dict_id = 0\n",
        "    data = Read_Data('movie.csv', ',') #change the delimiter based on your input file\n",
        "    data.pop(\"\\n\",None)\n",
        "    data.pop(\"\",None)\n",
        "    print('finished reading data..... \\n Starting mining .....')\n",
        "    eclat([], sorted(data.items(), key=lambda item: len(item[1]), reverse=True), dict_id)\n",
        "    print('found %d Frequent items' % len(FreqItems))\n",
        "    Rules = rules(FreqItems, confidence)\n",
        "    print('Writing Rules .....')\n",
        "\n",
        "\n",
        "\n",
        "    print_Frequent_Itemsets(output_FreqItems, FreqItems)\n",
        "    print_Rules(output_Rules, Rules)\n",
        "    Antecendent = getantecendent(FreqItems, confidence)\n",
        "    print_Antecendent(Antecendent)\n",
        "    \n",
        "    Ant1d = np.hstack(Antecendent)\n",
        "    \n",
        "    count = np.array(Ant1d)\n",
        "    unique, counts = np.unique(count, return_counts=True)\n",
        "    dict(zip(unique, counts))\n",
        "    counted = np.stack((unique, counts), axis=1)\n",
        "    appendFile = open('movie.csv','w')\n",
        "    for i in range(0,len(counted)):\n",
        "        appendFile.write(str(unique[i])+\";\"+str(counts[i])+\",\"+\"\\n\")\n",
        "    appendFile.close()\n",
        "    \n",
        "    df = pd.DataFrame(counted, columns=['word','counter'])\n",
        "    df[\"counter\"] = pd.to_numeric(df[\"counter\"])\n",
        "    sortcounted = df.sort_values([\"counter\"], axis=0, \n",
        "                     ascending=[False]) \n",
        "    elimcounted = sortcounted.drop(sortcounted[sortcounted['counter']<2].index)\n",
        "    \n",
        "    listfrequent = list(elimcounted.iloc[:, 0].values)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finished reading data..... \n",
            " Starting mining .....\n",
            "found 7022 Frequent items\n",
            "Found 435 Rules \n",
            "Writing Rules .....\n",
            "Print 435 attributes\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}